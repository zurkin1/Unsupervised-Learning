{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"recursion.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Uw-THBUkIXsW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"7462b446-6846-4893-f112-6054c0c491d8","executionInfo":{"status":"ok","timestamp":1572732008092,"user_tz":-120,"elapsed":28384,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ruwk4CRWxDGI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":800},"outputId":"b302b772-2c91-4246-8a29-f07b666b7684","executionInfo":{"status":"ok","timestamp":1572721601008,"user_tz":-120,"elapsed":35097,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}}},"source":["#From: https://www.kaggle.com/xhlulu/recursion-2019-load-resize-and-save-images/comments\n","!wget https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..uwK5YZgINjaSMqhH7c69XA.nVa6Awutx9LnuTX11tZx2FBawgzAUgfOmw19lFDTSZye4nmNDqvyNrxEp4qs2CtOhrAsQTv3FYylp_n-nbhee6dsv_R4YJwHtb6pKaks1B3c4XMr_FJwCsJI7hf_2EmSVQqrOJR5BlsUDeyLV99caNrJORRbXKjIO9BFK76V82cGfVIlr4WB1Y3_tGSA3UjNTG_iX7bg1oWchdS_QVIqFQ.enT5UPTT725ZjMUY8YS9CA/new_test.csv\n","!wget https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..bMSyme8vERvb9eFJP9XieA.WWuij9QzZVvjVrM9Qg6D6SrqujjA7AhpxwcJUkdeFTdMJMWR-LEjb4KpPHPZ7qCbtFAs8LO-hvga3qwZQZ5yOWZkNu0BDrqiCU8R7zVwjMWaINr9IezV2VwWT7DeFk9nUsAWKOKd-zRCCfb6-qcGhQx5thnDtbS2HKYptu6udoPTYjof_NH09z60AWC7LNAUozSr05GiZ3t5mfLJtCHm2A.9D86hvcqvLS6OvoY-fM6HQ/new_train.csv\n","!wget https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..hWNo2se6X9Ge8zGUV6Qzdg.VQ8IJfZkeidpju3CzlH1VQapPc3d4vxMgOFxtyuQmWy_czdLbKMNFGQ-hg-NuYJuez5Ha55Twcv2HmiHcsD87pySkLbZuBFQUh3TuogqILSRwwJRWKfIvhfAIjoZE6uIX8Z8j7nTt1Td9bK4Sd9RpbWCiGYDXfczFnpRT_yqjjBeAF2upuYo8jgpZ4tGePqXvAObgbfLpZSyNALoBXd8AA.wdnyPf_AyvvrMyxRxS_Sag/test.zip\n","!wget https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..Es8Z76BRaK-c1ibLL4FUvQ.IIAVPe4creXKB74jAau1SImZw1xhp-W36e9lMcpXhLLNXqDALsuyswh58N59RntwnlEl562nGSzDm76xfQu54hzqnzdkOwROBL8j-RIoCPuS9O8jUbmXvcuFOQWlGuJSkgbN2vaWu05tKFps_Ep8xUnU41WuYpLXWhidUVHsRtM605R51LbRxh4nvdR0eUAbO_L5OBDpwIiOUKbIIOTjGw.mfIXsAKnzaxrL5B7j_YQRQ/train.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2019-11-02 19:06:05--  https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..uwK5YZgINjaSMqhH7c69XA.nVa6Awutx9LnuTX11tZx2FBawgzAUgfOmw19lFDTSZye4nmNDqvyNrxEp4qs2CtOhrAsQTv3FYylp_n-nbhee6dsv_R4YJwHtb6pKaks1B3c4XMr_FJwCsJI7hf_2EmSVQqrOJR5BlsUDeyLV99caNrJORRbXKjIO9BFK76V82cGfVIlr4WB1Y3_tGSA3UjNTG_iX7bg1oWchdS_QVIqFQ.enT5UPTT725ZjMUY8YS9CA/new_test.csv\n","Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n","Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2042887 (1.9M) [text/csv]\n","Saving to: ‘new_test.csv’\n","\n","\rnew_test.csv          0%[                    ]       0  --.-KB/s               \rnew_test.csv         40%[=======>            ] 801.71K  3.91MB/s               \rnew_test.csv        100%[===================>]   1.95M  7.86MB/s    in 0.2s    \n","\n","2019-11-02 19:06:05 (7.86 MB/s) - ‘new_test.csv’ saved [2042887/2042887]\n","\n","--2019-11-02 19:06:06--  https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..bMSyme8vERvb9eFJP9XieA.WWuij9QzZVvjVrM9Qg6D6SrqujjA7AhpxwcJUkdeFTdMJMWR-LEjb4KpPHPZ7qCbtFAs8LO-hvga3qwZQZ5yOWZkNu0BDrqiCU8R7zVwjMWaINr9IezV2VwWT7DeFk9nUsAWKOKd-zRCCfb6-qcGhQx5thnDtbS2HKYptu6udoPTYjof_NH09z60AWC7LNAUozSr05GiZ3t5mfLJtCHm2A.9D86hvcqvLS6OvoY-fM6HQ/new_train.csv\n","Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n","Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4049635 (3.9M) [text/csv]\n","Saving to: ‘new_train.csv’\n","\n","new_train.csv       100%[===================>]   3.86M  14.6MB/s    in 0.3s    \n","\n","2019-11-02 19:06:06 (14.6 MB/s) - ‘new_train.csv’ saved [4049635/4049635]\n","\n","--2019-11-02 19:06:08--  https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..hWNo2se6X9Ge8zGUV6Qzdg.VQ8IJfZkeidpju3CzlH1VQapPc3d4vxMgOFxtyuQmWy_czdLbKMNFGQ-hg-NuYJuez5Ha55Twcv2HmiHcsD87pySkLbZuBFQUh3TuogqILSRwwJRWKfIvhfAIjoZE6uIX8Z8j7nTt1Td9bK4Sd9RpbWCiGYDXfczFnpRT_yqjjBeAF2upuYo8jgpZ4tGePqXvAObgbfLpZSyNALoBXd8AA.wdnyPf_AyvvrMyxRxS_Sag/test.zip\n","Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n","Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 976384332 (931M) [application/zip]\n","Saving to: ‘test.zip’\n","\n","test.zip            100%[===================>] 931.15M   100MB/s    in 9.7s    \n","\n","2019-11-02 19:06:17 (96.5 MB/s) - ‘test.zip’ saved [976384332/976384332]\n","\n","--2019-11-02 19:06:19--  https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..Es8Z76BRaK-c1ibLL4FUvQ.IIAVPe4creXKB74jAau1SImZw1xhp-W36e9lMcpXhLLNXqDALsuyswh58N59RntwnlEl562nGSzDm76xfQu54hzqnzdkOwROBL8j-RIoCPuS9O8jUbmXvcuFOQWlGuJSkgbN2vaWu05tKFps_Ep8xUnU41WuYpLXWhidUVHsRtM605R51LbRxh4nvdR0eUAbO_L5OBDpwIiOUKbIIOTjGw.mfIXsAKnzaxrL5B7j_YQRQ/train.zip\n","Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n","Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1815091687 (1.7G) [application/zip]\n","Saving to: ‘train.zip’\n","\n","train.zip           100%[===================>]   1.69G   101MB/s    in 19s     \n","\n","2019-11-02 19:06:38 (92.3 MB/s) - ‘train.zip’ saved [1815091687/1815091687]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3CMa4_s96Kr3","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"5801070b-eb27-45f2-83f4-13c587ef29e6","executionInfo":{"status":"ok","timestamp":1572721700418,"user_tz":-120,"elapsed":19540,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}}},"source":["!mkdir /tmp/data\n","!mv new_train.csv /tmp/data/train.csv\n","!mv new_test.csv /tmp/data/test.csv\n","!unzip -o test.zip -d /tmp/data | awk 'BEGIN {ORS=\" \"} {if(NR%500==0)print \".\"}'\n","!unzip -o train.zip -d /tmp/data | awk 'BEGIN {ORS=\" \"} {if(NR%500==0)print \".\"}'"],"execution_count":5,"outputs":[{"output_type":"stream","text":[". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . /bin/bash: aws: command not found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xxErG8au6L7j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"8070fbef-9cdb-44b2-90c0-3c85c3b0ba34","executionInfo":{"status":"ok","timestamp":1572721764583,"user_tz":-120,"elapsed":12123,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}}},"source":["!mkdir /tmp/data/train/HE\n","!mkdir /tmp/data/train/HU\n","!mkdir /tmp/data/train/RP\n","!mkdir /tmp/data/train/U2\n","!mv /tmp/data/train/HE* /tmp/data/train/HE/\n","!mv /tmp/data/train/HU* /tmp/data/train/HU/\n","!mv /tmp/data/train/RP* /tmp/data/train/RP/\n","!mv /tmp/data/train/U2* /tmp/data/train/U2"],"execution_count":7,"outputs":[{"output_type":"stream","text":["mv: cannot move '/tmp/data/train/HE' to a subdirectory of itself, '/tmp/data/train/HE/HE'\n","mv: cannot move '/tmp/data/train/HU' to a subdirectory of itself, '/tmp/data/train/HU/HU'\n","mv: cannot move '/tmp/data/train/RP' to a subdirectory of itself, '/tmp/data/train/RP/RP'\n","mv: cannot move '/tmp/data/train/U2' to a subdirectory of itself, '/tmp/data/train/U2/U2'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NQUazyCR7UGt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"8b480ada-1b52-4755-f198-5e4bac504c03","executionInfo":{"status":"ok","timestamp":1572721776475,"user_tz":-120,"elapsed":11038,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}}},"source":["!mkdir /tmp/data/test/HE\n","!mkdir /tmp/data/test/HU\n","!mkdir /tmp/data/test/RP\n","!mkdir /tmp/data/test/U2\n","!mv /tmp/data/test/HE* /tmp/data/test/HE/\n","!mv /tmp/data/test/HU* /tmp/data/test/HU/\n","!mv /tmp/data/test/RP* /tmp/data/test/RP/\n","!mv /tmp/data/test/U2* /tmp/data/test/U2"],"execution_count":8,"outputs":[{"output_type":"stream","text":["mv: cannot move '/tmp/data/test/HE' to a subdirectory of itself, '/tmp/data/test/HE/HE'\n","mv: cannot move '/tmp/data/test/HU' to a subdirectory of itself, '/tmp/data/test/HU/HU'\n","mv: cannot move '/tmp/data/test/RP' to a subdirectory of itself, '/tmp/data/test/RP/RP'\n","mv: cannot move '/tmp/data/test/U2' to a subdirectory of itself, '/tmp/data/test/U2/U2'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ttQiz8_u9Emi","colab_type":"code","colab":{}},"source":["import json\n","import cv2\n","import numpy as np\n","import keras\n","from keras.callbacks import Callback, ModelCheckpoint\n","from keras.models import Model, load_model\n","from keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, concatenate, Input, add, Activation, Conv2D, MaxPooling2D, Flatten\n","from keras.optimizers import Adam\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import cohen_kappa_score, accuracy_score\n","from skimage.io import imread\n","from keras.preprocessing.image import ImageDataGenerator\n","#!pip install --upgrade scikit-image\n","import multiprocessing\n","from PIL import Image\n","import tensorflow as tf\n","\n","BATCH_SIZE = 32\n","BASE_PATH = '/tmp/data'\n","\n","\n","class DataGenerator(keras.utils.Sequence):\n","    'Generates data for Keras'\n","\n","    def __init__(self, list_IDs, df, target_df=None, mode='train',\n","                 base_path=BASE_PATH,\n","                 batch_size=BATCH_SIZE, dim=(400, 400), n_channels=3, ext='jpeg',\n","                 rotation_range=0, fill_mode='nearest', swap=False,\n","                 vertical_flip=False, horizontal_flip=False, rescale=1 / 255.,\n","                 n_classes=5, random_state=2019, shuffle=True):\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.df = df\n","        self.mode = mode\n","        self.base_path = base_path\n","        self.rotation_range = rotation_range\n","        self.target_df = target_df\n","        self.list_IDs = list_IDs\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.ext = ext\n","        self.rescale = rescale\n","        self.vertical_flip = vertical_flip\n","        self.horizontal_flip = horizontal_flip\n","        self.random_state = random_state\n","        self.swap = swap\n","        self.fill_mode = self.__compute_fill_mode(fill_mode)\n","        np.random.seed(self.random_state)\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        #return 1000\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n","\n","        X = self.__generate_X(list_IDs_batch)\n","\n","        if self.mode == 'train' or self.mode == 'test':\n","            y = self.__generate_y(list_IDs_batch)\n","            return X, y\n","\n","        elif self.mode == 'predict':\n","            return X\n","        else:\n","            raise AttributeError('The parameter mode should be set to \"train\", \"test\" or \"predict\".')\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __generate_X(self, list_IDs_batch):\n","        'Generates data containing batch_size samples'\n","        # Initialization\n","        X_1 = np.empty((self.batch_size, *self.dim, self.n_channels))\n","        X_2 = np.empty((self.batch_size, *self.dim, self.n_channels))\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_batch):\n","            code = self.df['id_code'].iloc[ID]\n","            experiment = self.df['experiment'].iloc[ID]\n","            plate = self.df['plate'].iloc[ID]\n","            well = self.df['well'].iloc[ID]\n","            #site = np.random.randint(1, high=3)\n","\n","            #img1 = rio.load_site_as_rgb(self.mode, experiment, plate, well, 1, base_path=self.base_path)\n","            #img1 = img1.astype(np.uint8)\n","            #img1 = Image.fromarray(img1)\n","            #img2 = rio.load_site_as_rgb(self.mode, experiment, plate, well, 2, base_path=self.base_path)\n","            #img2 = img2.astype(np.uint8)\n","            #img2 = Image.fromarray(img2)\n","\n","            #print(f\"{self.base_path}/{self.mode}/{experiment}/Plate{plate}/{well}_s1_w1.{self.ext}\")\n","            #HEPG2-08_1_B03_s1.jpeg\n","            img_paths_1 = f\"{self.base_path}/{self.mode}/{experiment}_{plate}_{well}_s1.{self.ext}\"\n","            img_paths_2 = f\"{self.base_path}/{self.mode}/{experiment}_{plate}_{well}_s2.{self.ext}\"\n","\n","            img1 = self.__load_image(img_paths_1)\n","            img2 = self.__load_image(img_paths_2)\n","\n","            #if self.swap and np.random.rand() > 0.5:\n","            #    img1, img2 = img2, img1\n","\n","            # Store samples\n","            X_1[i] = img1\n","            X_2[i] = img2\n","\n","        return [X_1, X_2]\n","\n","    def __generate_y(self, list_IDs_batch):\n","        y = np.empty((self.batch_size, self.n_classes), dtype=int)\n","\n","        for i, ID in enumerate(list_IDs_batch):\n","            sirna = self.target_df.iloc[ID]\n","            y[i,] = sirna\n","\n","        return y\n","\n","    def __load_image(self, img_path):\n","        img = cv2.imread(img_path)\n","        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        #img = self.rescale * img.astype(np.float32)\n","        return img\n","        #n_channels = len(img_paths)\n","        #data = np.ndarray(shape=(512, 512, n_channels), dtype=np.uint8)\n","        #for ix, img_path in enumerate(img_paths):\n","        #    with tf.io.gfile.GFile(img_path, 'rb') as f:\n","        #       img = imread(f, format='png')\n","        #    data[:, :, ix] = img\n","        #return data\n","\n","\n","    def __compute_fill_mode(self, fill_mode):\n","    #    convert_cv2 = {\n","    #        'nearest': cv2.BORDER_REPLICATE,\n","    #        'reflect': cv2.BORDER_REFLECT,\n","    #        'wrap': cv2.BORDER_WRAP,\n","    #        'constant': cv2.BORDER_CONSTANT\n","    #    }\n","    #    return convert_cv2[fill_mode]\n","        pass\n","\n","    #def __random_transform(self, img):\n","    #    if np.random.rand() > 0.5 and self.vertical_flip:\n","    #        img = cv2.flip(img, 0)\n","    #    if np.random.rand() > 0.5 and self.horizontal_flip:\n","    #        img = cv2.flip(img, 1)\n","\n","        # Random Rotation\n","    #    rotation = self.rotation_range * np.random.rand()\n","\n","    #    rows, cols = img.shape[:2]\n","    #    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation, 1)\n","    #    img = cv2.warpAffine(img, M, (cols, rows), borderMode=self.fill_mode)\n","\n","    #    return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4A8KYdHi9XVM","colab_type":"code","colab":{}},"source":["def build_model(n_classes, input_shape=(224, 224, 3)):\n","    im_inp_1 = Input(shape=input_shape)\n","    #im_inp_2 = Input(shape=input_shape)\n","\n","    conv_1 = Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu')\n","    mp_1 = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding = 'valid')\n","    bn_1 = BatchNormalization()\n","\n","    conv_2 = Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation='relu') #11\n","    mp_2 = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding = 'valid')\n","    bn_2 = BatchNormalization()\n","\n","    conv_3 = Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu') #5\n","    bn_3 = BatchNormalization()\n","\n","    #conv_4 = Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu')\n","    #bn_4 = BatchNormalization()\n","\n","    #conv_5 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu')\n","    #mp_5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n","    #bn_5 = BatchNormalization()\n","\n","    gl_1 = GlobalAveragePooling2D()\n","    fl_1 = Flatten()\n","    dn_1 = Dense(4096, input_shape=(224 * 224 * 3,), activation='relu')\n","\n","\n","    #x1 = dn_1(fl_1(bn_5(mp_5(conv_5(bn_4(conv_4(bn_3(conv_3(bn_2(mp_2(conv_2(bn_1(mp_1(conv_1(im_inp_1)))))))))))))))\n","    x1 = dn_1(gl_1(bn_3(conv_3(bn_2(mp_2(conv_2(bn_1(mp_1(conv_1(im_inp_1))))))))))\n","    #x2 = dn_1(gl_1(bn_3(conv_3(bn_2(mp_2(conv_2(bn_1(mp_1(conv_1(im_inp_2))))))))))\n","\n","    #x1 = GlobalAveragePooling2D()(x1)\n","    #x2 = GlobalAveragePooling2D()(x2)\n","\n","    #x = add([x1, x2])\n","    x = Dense(2048, activation='relu')(x1)\n","    #x = Dropout(0.4)(x)\n","    x = Dense(1024, activation='relu')(x)\n","    #x = Dropout(0.4)(x)\n","    out = Dense(n_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=[im_inp_1], outputs=out) #, im_inp_2\n","    model.compile(Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaVTCdW29j0a","colab_type":"code","outputId":"0f91f270-fab3-4b66-d2e3-ab8a4607439d","executionInfo":{"status":"ok","timestamp":1572731770947,"user_tz":-120,"elapsed":9978229,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import json\n","#import cv2\n","import numpy as np\n","import keras\n","from keras.callbacks import Callback, ModelCheckpoint\n","from keras.models import Model, load_model\n","from keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, concatenate, Input, add, Activation, Conv2D, MaxPooling2D, Flatten\n","from keras.optimizers import Adam\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import cohen_kappa_score, accuracy_score\n","#from skimage.io import imread\n","from keras.preprocessing.image import ImageDataGenerator\n","#!pip install --upgrade scikit-image\n","import multiprocessing\n","#from PIL import Image\n","import tensorflow as tf\n","\n","BATCH_SIZE = 32\n","BASE_PATH = '/tmp/data'\n","\n","#Preprocessing.\n","train_df = pd.read_csv(BASE_PATH+'/train.csv')\n","test_df = pd.read_csv(BASE_PATH+'/test.csv')\n","train_df['category'] = train_df['experiment'].apply(lambda x: x.split('-')[0])\n","test_df['category'] = test_df['experiment'].apply(lambda x: x.split('-')[0])\n","train_df['cell'] = train_df.id_code.str[0:2]\n","test_df['cell'] = test_df.id_code.str[0:2]\n","train_target_df = pd.get_dummies(train_df.cell)\n","test_target_df = pd.get_dummies(test_df.cell)\n","train_idx, val_idx = train_test_split(train_df.index, test_size=0.15, random_state=2019)\n","print(train_idx.shape, val_idx.shape) #(31037,) (5478,) (62075,) (10955,)\n","\n","#train_generator = DataGenerator(train_idx, mode='train', df=train_df, target_df=train_target_df, n_classes=train_target_df.shape[1])\n","#val_generator = DataGenerator(val_idx, mode='test', df=test_df, target_df=test_target_df, n_classes=test_target_df.shape[1])\n","\n","train_datagen = ImageDataGenerator(\n","        #rescale=1./255,\n","        #shear_range=0,\n","        #zoom_range=0,\n","        #horizontal_flip=False\n","        #width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        #height_shift_range=0.1\n","        )  # randomly shift images vertically (fraction of total height))\n","\n","val_datagen = ImageDataGenerator() #rescale=1./255  \n","\n","train_generator = train_datagen.flow_from_directory(\n","        BASE_PATH+'/train',\n","        target_size=(400, 400),\n","        batch_size=32,\n","        shuffle=False)\n","\n","val_generator = val_datagen.flow_from_directory(\n","        BASE_PATH+'/test',\n","        target_size=(400, 400),\n","        batch_size=32,\n","        shuffle=False)\n","\n","model = build_model(input_shape=(400, 400, 3), n_classes=train_target_df.shape[1])\n","#model = load_model('model.h5')\n","model.summary()\n","\n","#Train.\n","checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n","history = model.fit_generator(train_generator, validation_data=val_generator, callbacks=[checkpoint], use_multiprocessing=True, verbose=1, epochs=10)\n","\n","with open('history.json', 'w') as f:\n","    json.dump(history.history, f)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["(62075,) (10955,)\n","Found 73030 images belonging to 4 classes.\n","Found 39794 images belonging to 4 classes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 400, 400, 3)       0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 98, 98, 96)        34944     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 49, 49, 96)        0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 49, 49, 96)        384       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 45, 45, 256)       614656    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 22, 22, 256)       0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 22, 22, 256)       1024      \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 20, 20, 384)       885120    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 20, 20, 384)       1536      \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 384)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4096)              1576960   \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2048)              8390656   \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1024)              2098176   \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4)                 4100      \n","=================================================================\n","Total params: 13,607,556\n","Trainable params: 13,606,084\n","Non-trainable params: 1,472\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/10\n","2282/2283 [============================>.] - ETA: 0s - loss: 0.5515 - acc: 0.7875\n","2283/2283 [==============================] - 1051s 460ms/step - loss: 0.5513 - acc: 0.7876 - val_loss: 4.7541 - val_acc: 0.1680\n","\n","Epoch 00001: val_loss improved from inf to 4.75408, saving model to model.h5\n","Epoch 2/10\n","2283/2283 [==============================] - 1022s 448ms/step - loss: 0.1737 - acc: 0.9383 - val_loss: 5.6897 - val_acc: 0.1775\n","\n","Epoch 00002: val_loss did not improve from 4.75408\n","Epoch 3/10\n","2283/2283 [==============================] - 984s 431ms/step - loss: 0.1140 - acc: 0.9636 - val_loss: 4.6772 - val_acc: 0.2042\n","\n","Epoch 00003: val_loss improved from 4.75408 to 4.67715, saving model to model.h5\n","Epoch 4/10\n","2283/2283 [==============================] - 982s 430ms/step - loss: 0.0973 - acc: 0.9715 - val_loss: 3.3118 - val_acc: 0.3088\n","\n","Epoch 00004: val_loss improved from 4.67715 to 3.31183, saving model to model.h5\n","Epoch 5/10\n","2283/2283 [==============================] - 980s 429ms/step - loss: 0.0609 - acc: 0.9830 - val_loss: 4.0222 - val_acc: 0.3748\n","\n","Epoch 00005: val_loss did not improve from 3.31183\n","Epoch 6/10\n","2283/2283 [==============================] - 982s 430ms/step - loss: 0.0522 - acc: 0.9860 - val_loss: 4.7659 - val_acc: 0.2675\n","\n","Epoch 00006: val_loss did not improve from 3.31183\n","Epoch 7/10\n","2283/2283 [==============================] - 986s 432ms/step - loss: 0.0460 - acc: 0.9874 - val_loss: 5.9920 - val_acc: 0.2923\n","\n","Epoch 00007: val_loss did not improve from 3.31183\n","Epoch 8/10\n","2283/2283 [==============================] - 992s 435ms/step - loss: 0.0432 - acc: 0.9890 - val_loss: 6.1374 - val_acc: 0.2550\n","\n","Epoch 00008: val_loss did not improve from 3.31183\n","Epoch 9/10\n","2283/2283 [==============================] - 991s 434ms/step - loss: 0.0519 - acc: 0.9875 - val_loss: 4.8110 - val_acc: 0.3521\n","\n","Epoch 00009: val_loss did not improve from 3.31183\n","Epoch 10/10\n","2283/2283 [==============================] - 993s 435ms/step - loss: 0.0240 - acc: 0.9938 - val_loss: 2.9105 - val_acc: 0.2351\n","\n","Epoch 00010: val_loss improved from 3.31183 to 2.91052, saving model to model.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tCxbLiQ8_WYK","colab_type":"code","colab":{}},"source":["!cp model.h5 /content/drive/My\\ Drive/model.h5"],"execution_count":0,"outputs":[]}]}