{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"recursion.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Uw-THBUkIXsW","colab_type":"code","outputId":"55d97769-1ffa-4429-9107-60581e50471c","executionInfo":{"status":"ok","timestamp":1572946605681,"user_tz":-120,"elapsed":25317,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5CENSa_fkvv-","colab_type":"code","outputId":"cd0607ca-3f40-4826-ae4a-c8216dd00132","executionInfo":{"status":"ok","timestamp":1572773364607,"user_tz":-120,"elapsed":211941,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["!cp '/content/drive/My Drive/Colab Notebooks/recursion3.zip' .\n","!mkdir /tmp/data\n","!unzip -o recursion3.zip -d /tmp/data | awk 'BEGIN {ORS=\" \"} {if(NR%500==0)print \".\"}'"],"execution_count":0,"outputs":[{"output_type":"stream","text":[". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4A8KYdHi9XVM","colab_type":"code","colab":{}},"source":["import json\n","import numpy as np\n","import keras\n","from keras.callbacks import Callback, ModelCheckpoint\n","from keras.models import Model, load_model\n","from keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, concatenate, Input, add, Activation, Conv2D, MaxPooling2D, Flatten\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import cohen_kappa_score, accuracy_score\n","#!pip install --upgrade scikit-image\n","import multiprocessing\n","import random\n","import os\n","\n","\n","BATCH_SIZE = 16\n","BASE_PATH = '/tmp/data'\n","NUM_IMAGES_TRAIN = 73030\n","NUM_IMAGES_TEST = 39794\n","\n","\n","def build_model(n_classes, input_shape=(224, 224, 3)):\n","    im_inp_1 = Input(shape=input_shape)\n","    im_inp_2 = Input(shape=input_shape)\n","\n","    conv_1 = Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu')\n","    mp_1 = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding = 'valid')\n","    bn_1 = BatchNormalization()\n","\n","    conv_2 = Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation='relu') #11\n","    mp_2 = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding = 'valid')\n","    bn_2 = BatchNormalization()\n","\n","    conv_3 = Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu') #5\n","    bn_3 = BatchNormalization()\n","\n","    #conv_4 = Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu')\n","    #bn_4 = BatchNormalization()\n","\n","    #conv_5 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu')\n","    #mp_5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n","    #bn_5 = BatchNormalization()\n","\n","    gl_1 = GlobalAveragePooling2D()\n","    fl_1 = Flatten()\n","    dn_1 = Dense(4096, input_shape=(224 * 224 * 3,), activation='relu')\n","\n","\n","    #x1 = dn_1(fl_1(bn_5(mp_5(conv_5(bn_4(conv_4(bn_3(conv_3(bn_2(mp_2(conv_2(bn_1(mp_1(conv_1(im_inp_1)))))))))))))))\n","    x1 = dn_1(gl_1(bn_3(conv_3(bn_2(mp_2(conv_2(bn_1(mp_1(conv_1(im_inp_1))))))))))\n","    x2 = dn_1(gl_1(bn_3(conv_3(bn_2(mp_2(conv_2(bn_1(mp_1(conv_1(im_inp_2))))))))))\n","\n","    #x1 = GlobalAveragePooling2D()(x1)\n","    #x2 = GlobalAveragePooling2D()(x2)\n","\n","    x = add([x1, x2])\n","    x = Dense(2048, activation='relu')(x)\n","    #x = Dropout(0.4)(x)\n","    x = Dense(1024, activation='relu')(x)\n","    #x = Dropout(0.4)(x)\n","    out = Dense(n_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=[im_inp_1, im_inp_2], outputs=out)\n","    model.compile(Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaVTCdW29j0a","colab_type":"code","outputId":"172ee5c1-3386-4176-c79c-b45844d02c33","executionInfo":{"status":"ok","timestamp":1572777411815,"user_tz":-120,"elapsed":4002992,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def generator_multiple(generator, mode, target_size=(133,133)):\n","    genX1 = generator.flow_from_directory(BASE_PATH+'/'+mode+'_center', target_size=target_size, batch_size=BATCH_SIZE, shuffle=False)\n","    genX2 = generator.flow_from_directory(BASE_PATH+'/'+mode+'_random', target_size=target_size, batch_size=BATCH_SIZE, shuffle=False)\n","    while True:\n","        X1i = genX1.next()\n","        X2i = genX2.next()\n","        yield [X1i[0], X2i[0]], X2i[1] #Yield both images and theor mutual label.\n","\n","train_datagen = ImageDataGenerator()\n","val_datagen = ImageDataGenerator()\n","traingenerator = generator_multiple(generator=train_datagen, mode='train')\n","valgenerator = generator_multiple(generator=val_datagen, mode='test')\n","model = build_model(input_shape=(133, 133, 3), n_classes=8)\n","#model = load_model('model.h5')\n","model.summary()\n","\n","#Train.\n","checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n","history = model.fit_generator(traingenerator,\n","                              steps_per_epoch=NUM_IMAGES_TRAIN/BATCH_SIZE,\n","                              validation_data=valgenerator,\n","                              validation_steps=NUM_IMAGES_TEST/BATCH_SIZE,\n","                              callbacks=[checkpoint],\n","                              #use_multiprocessing=True,\n","                              #workers=multiprocessing.cpu_count()-1,\n","                              verbose=1,\n","                              epochs=10)\n","\n","with open('history.json', 'w') as f:\n","    json.dump(history.history, f)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 133, 133, 3)  0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 133, 133, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 31, 31, 96)   34944       input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 96)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_1[1][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 15, 15, 96)   384         max_pooling2d_1[0][0]            \n","                                                                 max_pooling2d_1[1][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 11, 11, 256)  614656      batch_normalization_1[0][0]      \n","                                                                 batch_normalization_1[1][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 256)    0           conv2d_2[0][0]                   \n","                                                                 conv2d_2[1][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 256)    1024        max_pooling2d_2[0][0]            \n","                                                                 max_pooling2d_2[1][0]            \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 3, 3, 384)    885120      batch_normalization_2[0][0]      \n","                                                                 batch_normalization_2[1][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 3, 3, 384)    1536        conv2d_3[0][0]                   \n","                                                                 conv2d_3[1][0]                   \n","__________________________________________________________________________________________________\n","global_average_pooling2d_1 (Glo (None, 384)          0           batch_normalization_3[0][0]      \n","                                                                 batch_normalization_3[1][0]      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 4096)         1576960     global_average_pooling2d_1[0][0] \n","                                                                 global_average_pooling2d_1[1][0] \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 4096)         0           dense_1[0][0]                    \n","                                                                 dense_1[1][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 2048)         8390656     add_1[0][0]                      \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         2098176     dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 8)            8200        dense_3[0][0]                    \n","==================================================================================================\n","Total params: 13,611,656\n","Trainable params: 13,610,184\n","Non-trainable params: 1,472\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/10\n","Found 39794 images belonging to 8 classes.\n","Found 73030 images belonging to 8 classes.\n","Found 39794 images belonging to 8 classes.\n","Found 73030 images belonging to 8 classes.\n","4565/4564 [==============================] - 427s 94ms/step - loss: 12.4200 - acc: 0.2290 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00001: val_loss improved from inf to 14.11478, saving model to model.h5\n","Epoch 2/10\n","4565/4564 [==============================] - 425s 93ms/step - loss: 14.0861 - acc: 0.1261 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00002: val_loss did not improve from 14.11478\n","Epoch 3/10\n","4565/4564 [==============================] - 411s 90ms/step - loss: 14.0861 - acc: 0.1261 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00003: val_loss did not improve from 14.11478\n","Epoch 4/10\n","4565/4564 [==============================] - 397s 87ms/step - loss: 14.0861 - acc: 0.1261 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00004: val_loss did not improve from 14.11478\n","Epoch 5/10\n","4565/4564 [==============================] - 391s 86ms/step - loss: 14.0861 - acc: 0.1261 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00005: val_loss did not improve from 14.11478\n","Epoch 6/10\n","4565/4564 [==============================] - 392s 86ms/step - loss: 14.0861 - acc: 0.1261 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00006: val_loss did not improve from 14.11478\n","Epoch 7/10\n","4565/4564 [==============================] - 389s 85ms/step - loss: 14.0861 - acc: 0.1261 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00007: val_loss did not improve from 14.11478\n","Epoch 8/10\n","4565/4564 [==============================] - 387s 85ms/step - loss: 14.0861 - acc: 0.1261 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00008: val_loss did not improve from 14.11478\n","Epoch 9/10\n","4565/4564 [==============================] - 387s 85ms/step - loss: 14.0861 - acc: 0.1261 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00009: val_loss did not improve from 14.11478\n","Epoch 10/10\n","4565/4564 [==============================] - 387s 85ms/step - loss: 14.0861 - acc: 0.1261 - val_loss: 14.1148 - val_acc: 0.1243\n","\n","Epoch 00010: val_loss did not improve from 14.11478\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tCxbLiQ8_WYK","colab_type":"code","colab":{}},"source":["!cp model.h5 /content/drive/My\\ Drive/model.h5"],"execution_count":0,"outputs":[]}]}