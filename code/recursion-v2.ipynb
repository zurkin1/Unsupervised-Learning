{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"recursion.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"-HPZv9654Uos","colab_type":"code","colab":{}},"source":["!pip install gcsfs\n","import pandas as pd\n","\n","# Download the file from a given Google Cloud Storage bucket.\n","train_df = pd.read_csv('gs://rxrx1-europe-west4/metadata/train.csv')\n","train_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ruwk4CRWxDGI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":800},"outputId":"5cd36c5d-06e3-4e8d-8276-cd833adf8199","executionInfo":{"status":"ok","timestamp":1572692454385,"user_tz":-120,"elapsed":57153,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}}},"source":["#From: https://www.kaggle.com/xhlulu/recursion-2019-load-resize-and-save-images/comments\n","!wget https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..C4a3vui5LZ8k7_CmVPbc5g.zA4Yl5OkPllqN-m5R9UgoFgTZI3Oq31DDJ0crQ_w5zFaZxCQaFkHnLtWFEu0H4X5awqos1eON8o2Rmg1Y-7L4Lowz6CGvDbg4C2ruCNC943ZsWYwsagUOuXJSpa97u36wVpyi7cOgDsSD5aIxox8vhihQ_qeHSc94ElESJ3PzJUWCejJiA_ebfyckiy0cInJ5JlHxSYm-WzH-UAwdr6Z-A.TjCuMojSlvlNyyAvlZGzsw/new_test.csv\n","!wget https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..mXgoyrLHqxle4mduZii4Gw.KaCNzIU3ITEmb_pZHjNTD0zFALw-KVutOTuMYMudtR6gHhkUviiaUktILawmYsTm8uoZ7da4ta8xaR2v1sxDOSqKamqbWKuObicHKC-DJkj_fFcCu3zk5xhRo4VQgJy6G57QcLwj2UNmI0WINpGpXSwBn8U6Z0bLMy2-KeAcMeALPdN875lnagbQZVZ_qjEFzaQofsm30--M6KrM2yl0jw.yOrgL3Pk8ejz46Avdmj5-A/new_train.csv\n","!wget https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..TFRVcHoh7Lhc41Tgty7fPw.y-LvUOo_Ya6Y5dh4Uf1NvGw3IEUX6OTvFm6mj9v66itjLEG4K1n6Qsp1PxuH4aVKImQYaDVJgAPLAgRd_tY-xw_JcVWkBzHoPeNo0Umov1ePbtcCLtmw48_0uepXAntvMsM75sBwfKRc6vt0AqAgQMs6RnzQV2FrWFPh5U0bMao8_xg2Lw6_w0-6aLcYwdw5vwptMmd-f6N6Ad95HMmUig.P3IvMb-hZ31jvXbul1Q8oA/test.zip\n","!wget https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..GeZvigRDsdrVowPzseFr2A.FXfKnFTOhrMIKsSbpIsTIVHqe0DF5zmH7gvJ1kQ08IHOJRygQgxIBMvMOndd1zehoT-4YF-FHiZz3D36-VVyb1lA4A-x7vI7dSRh0ykj45ZipSF8t3aVn55kwybyZbQAxxldTrVKWljmgyshHGDp4mruK-ORbcktSzkXIriXW_LxImOKqJ_EN4Ozn-obG4_55fROMPwh3pyzFAiNtFLQsw.7L0s3E_RbcwwYuwHnrDopQ/train.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2019-11-02 10:59:56--  https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..C4a3vui5LZ8k7_CmVPbc5g.zA4Yl5OkPllqN-m5R9UgoFgTZI3Oq31DDJ0crQ_w5zFaZxCQaFkHnLtWFEu0H4X5awqos1eON8o2Rmg1Y-7L4Lowz6CGvDbg4C2ruCNC943ZsWYwsagUOuXJSpa97u36wVpyi7cOgDsSD5aIxox8vhihQ_qeHSc94ElESJ3PzJUWCejJiA_ebfyckiy0cInJ5JlHxSYm-WzH-UAwdr6Z-A.TjCuMojSlvlNyyAvlZGzsw/new_test.csv\n","Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n","Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2042887 (1.9M) [text/csv]\n","Saving to: ‘new_test.csv.1’\n","\n","\rnew_test.csv.1        0%[                    ]       0  --.-KB/s               \rnew_test.csv.1       36%[======>             ] 726.97K  3.55MB/s               \rnew_test.csv.1      100%[===================>]   1.95M  7.73MB/s    in 0.3s    \n","\n","2019-11-02 10:59:56 (7.73 MB/s) - ‘new_test.csv.1’ saved [2042887/2042887]\n","\n","--2019-11-02 10:59:57--  https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..mXgoyrLHqxle4mduZii4Gw.KaCNzIU3ITEmb_pZHjNTD0zFALw-KVutOTuMYMudtR6gHhkUviiaUktILawmYsTm8uoZ7da4ta8xaR2v1sxDOSqKamqbWKuObicHKC-DJkj_fFcCu3zk5xhRo4VQgJy6G57QcLwj2UNmI0WINpGpXSwBn8U6Z0bLMy2-KeAcMeALPdN875lnagbQZVZ_qjEFzaQofsm30--M6KrM2yl0jw.yOrgL3Pk8ejz46Avdmj5-A/new_train.csv\n","Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n","Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4049635 (3.9M) [text/csv]\n","Saving to: ‘new_train.csv’\n","\n","new_train.csv       100%[===================>]   3.86M  13.7MB/s    in 0.3s    \n","\n","2019-11-02 10:59:58 (13.7 MB/s) - ‘new_train.csv’ saved [4049635/4049635]\n","\n","--2019-11-02 10:59:59--  https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..TFRVcHoh7Lhc41Tgty7fPw.y-LvUOo_Ya6Y5dh4Uf1NvGw3IEUX6OTvFm6mj9v66itjLEG4K1n6Qsp1PxuH4aVKImQYaDVJgAPLAgRd_tY-xw_JcVWkBzHoPeNo0Umov1ePbtcCLtmw48_0uepXAntvMsM75sBwfKRc6vt0AqAgQMs6RnzQV2FrWFPh5U0bMao8_xg2Lw6_w0-6aLcYwdw5vwptMmd-f6N6Ad95HMmUig.P3IvMb-hZ31jvXbul1Q8oA/test.zip\n","Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n","Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 976384332 (931M) [application/zip]\n","Saving to: ‘test.zip’\n","\n","test.zip            100%[===================>] 931.15M  95.2MB/s    in 11s     \n","\n","2019-11-02 11:00:10 (88.5 MB/s) - ‘test.zip’ saved [976384332/976384332]\n","\n","--2019-11-02 11:00:11--  https://www.kaggleusercontent.com/kf/18332860/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..GeZvigRDsdrVowPzseFr2A.FXfKnFTOhrMIKsSbpIsTIVHqe0DF5zmH7gvJ1kQ08IHOJRygQgxIBMvMOndd1zehoT-4YF-FHiZz3D36-VVyb1lA4A-x7vI7dSRh0ykj45ZipSF8t3aVn55kwybyZbQAxxldTrVKWljmgyshHGDp4mruK-ORbcktSzkXIriXW_LxImOKqJ_EN4Ozn-obG4_55fROMPwh3pyzFAiNtFLQsw.7L0s3E_RbcwwYuwHnrDopQ/train.zip\n","Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n","Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1815091687 (1.7G) [application/zip]\n","Saving to: ‘train.zip’\n","\n","train.zip           100%[===================>]   1.69G  22.4MB/s    in 41s     \n","\n","2019-11-02 11:00:52 (42.3 MB/s) - ‘train.zip’ saved [1815091687/1815091687]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TykIpTQ11tZb","colab_type":"code","colab":{}},"source":["!mv new_train.csv /tmp/data/train.csv\n","!mv new_test.csv /tmp/data/test.csv\n","!mkdir /tmp/data\n","!unzip test.zip -d /tmp/data\n","!unzip train.zip -d /tmp/data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttQiz8_u9Emi","colab_type":"code","colab":{}},"source":["import json\n","import cv2\n","import numpy as np\n","import keras\n","from keras.callbacks import Callback, ModelCheckpoint\n","from keras.models import Model, load_model\n","from keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, concatenate, Input, add, Activation, Conv2D, MaxPooling2D, Flatten\n","from keras.optimizers import Adam\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import cohen_kappa_score, accuracy_score\n","from skimage.io import imread\n","#!pip install --upgrade scikit-image\n","import multiprocessing\n","from PIL import Image\n","import tensorflow as tf\n","\n","BATCH_SIZE = 32\n","BASE_PATH = '/tmp/data'\n","\n","\n","class DataGenerator(keras.utils.Sequence):\n","    'Generates data for Keras'\n","\n","    def __init__(self, list_IDs, df, target_df=None, mode='train',\n","                 base_path=BASE_PATH,\n","                 batch_size=BATCH_SIZE, dim=(400, 400), n_channels=3, ext='jpeg',\n","                 rotation_range=0, fill_mode='nearest', swap=False,\n","                 vertical_flip=False, horizontal_flip=False, rescale=1 / 255.,\n","                 n_classes=5, random_state=2019, shuffle=True):\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.df = df\n","        self.mode = mode\n","        self.base_path = base_path\n","        self.rotation_range = rotation_range\n","        self.target_df = target_df\n","        self.list_IDs = list_IDs\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.ext = ext\n","        self.rescale = rescale\n","        self.vertical_flip = vertical_flip\n","        self.horizontal_flip = horizontal_flip\n","        self.random_state = random_state\n","        self.swap = swap\n","        self.fill_mode = self.__compute_fill_mode(fill_mode)\n","        np.random.seed(self.random_state)\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        #return 1000\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n","\n","        X = self.__generate_X(list_IDs_batch)\n","\n","        if self.mode == 'train' or self.mode == 'test':\n","            y = self.__generate_y(list_IDs_batch)\n","            return X, y\n","\n","        elif self.mode == 'predict':\n","            return X\n","        else:\n","            raise AttributeError('The parameter mode should be set to \"train\", \"test\" or \"predict\".')\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __generate_X(self, list_IDs_batch):\n","        'Generates data containing batch_size samples'\n","        # Initialization\n","        X_1 = np.empty((self.batch_size, *self.dim, self.n_channels))\n","        X_2 = np.empty((self.batch_size, *self.dim, self.n_channels))\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_batch):\n","            code = self.df['id_code'].iloc[ID]\n","            experiment = self.df['experiment'].iloc[ID]\n","            plate = self.df['plate'].iloc[ID]\n","            well = self.df['well'].iloc[ID]\n","            #site = np.random.randint(1, high=3)\n","\n","            #img1 = rio.load_site_as_rgb(self.mode, experiment, plate, well, 1, base_path=self.base_path)\n","            #img1 = img1.astype(np.uint8)\n","            #img1 = Image.fromarray(img1)\n","            #img2 = rio.load_site_as_rgb(self.mode, experiment, plate, well, 2, base_path=self.base_path)\n","            #img2 = img2.astype(np.uint8)\n","            #img2 = Image.fromarray(img2)\n","\n","            #print(f\"{self.base_path}/{self.mode}/{experiment}/Plate{plate}/{well}_s1_w1.{self.ext}\")\n","            #HEPG2-08_1_B03_s1.jpeg\n","            img_paths_1 = f\"{self.base_path}/{self.mode}/{experiment}_{plate}_{well}_s1.{self.ext}\"\n","            img_paths_2 = f\"{self.base_path}/{self.mode}/{experiment}_{plate}_{well}_s2.{self.ext}\"\n","\n","            img1 = self.__load_image(img_paths_1)\n","            img2 = self.__load_image(img_paths_2)\n","\n","            #if self.swap and np.random.rand() > 0.5:\n","            #    img1, img2 = img2, img1\n","\n","            # Store samples\n","            X_1[i] = img1\n","            X_2[i] = img2\n","\n","        return [X_1, X_2]\n","\n","    def __generate_y(self, list_IDs_batch):\n","        y = np.empty((self.batch_size, self.n_classes), dtype=int)\n","\n","        for i, ID in enumerate(list_IDs_batch):\n","            sirna = self.target_df.iloc[ID]\n","            y[i,] = sirna\n","\n","        return y\n","\n","    def __load_image(self, img_path):\n","        img = cv2.imread(img_path)\n","        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        #img = self.rescale * img.astype(np.float32)\n","        return img\n","        #n_channels = len(img_paths)\n","        #data = np.ndarray(shape=(512, 512, n_channels), dtype=np.uint8)\n","        #for ix, img_path in enumerate(img_paths):\n","        #    with tf.io.gfile.GFile(img_path, 'rb') as f:\n","        #       img = imread(f, format='png')\n","        #    data[:, :, ix] = img\n","        #return data\n","\n","\n","    def __compute_fill_mode(self, fill_mode):\n","    #    convert_cv2 = {\n","    #        'nearest': cv2.BORDER_REPLICATE,\n","    #        'reflect': cv2.BORDER_REFLECT,\n","    #        'wrap': cv2.BORDER_WRAP,\n","    #        'constant': cv2.BORDER_CONSTANT\n","    #    }\n","    #    return convert_cv2[fill_mode]\n","        pass\n","\n","    #def __random_transform(self, img):\n","    #    if np.random.rand() > 0.5 and self.vertical_flip:\n","    #        img = cv2.flip(img, 0)\n","    #    if np.random.rand() > 0.5 and self.horizontal_flip:\n","    #        img = cv2.flip(img, 1)\n","\n","        # Random Rotation\n","    #    rotation = self.rotation_range * np.random.rand()\n","\n","    #    rows, cols = img.shape[:2]\n","    #    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation, 1)\n","    #    img = cv2.warpAffine(img, M, (cols, rows), borderMode=self.fill_mode)\n","\n","    #    return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4A8KYdHi9XVM","colab_type":"code","colab":{}},"source":["def build_model(n_classes, input_shape=(224, 224, 3)):\n","    im_inp_1 = Input(shape=input_shape)\n","    im_inp_2 = Input(shape=input_shape)\n","\n","    conv_1 = Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu')\n","    mp_1 = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding = 'valid')\n","    bn_1 = BatchNormalization()\n","\n","    conv_2 = Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation='relu') #11\n","    mp_2 = MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding = 'valid')\n","    bn_2 = BatchNormalization()\n","\n","    conv_3 = Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu') #5\n","    bn_3 = BatchNormalization()\n","\n","    #conv_4 = Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu')\n","    #bn_4 = BatchNormalization()\n","\n","    #conv_5 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu')\n","    #mp_5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n","    #bn_5 = BatchNormalization()\n","\n","    gl_1 = GlobalAveragePooling2D()\n","    fl_1 = Flatten()\n","    dn_1 = Dense(4096, input_shape=(224 * 224 * 3,), activation='relu')\n","\n","\n","    #x1 = dn_1(fl_1(bn_5(mp_5(conv_5(bn_4(conv_4(bn_3(conv_3(bn_2(mp_2(conv_2(bn_1(mp_1(conv_1(im_inp_1)))))))))))))))\n","    x1 = dn_1(gl_1(bn_3(conv_3(bn_2(mp_2(conv_2(bn_1(mp_1(conv_1(im_inp_1))))))))))\n","    x2 = dn_1(gl_1(bn_3(conv_3(bn_2(mp_2(conv_2(bn_1(mp_1(conv_1(im_inp_2))))))))))\n","\n","    #x1 = GlobalAveragePooling2D()(x1)\n","    #x2 = GlobalAveragePooling2D()(x2)\n","\n","    x = add([x1, x2])\n","    x = Dense(2048, activation='relu')(x)\n","    #x = Dropout(0.4)(x)\n","    x = Dense(1024, activation='relu')(x)\n","    #x = Dropout(0.4)(x)\n","    out = Dense(n_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=[im_inp_1, im_inp_2], outputs=out)\n","    model.compile(Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaVTCdW29j0a","colab_type":"code","outputId":"cc6a5176-8797-4f83-df2f-1a436c83142f","executionInfo":{"status":"error","timestamp":1572651098533,"user_tz":-120,"elapsed":2485207,"user":{"displayName":"D L","photoUrl":"","userId":"01853311397766446781"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#Preprocessing.\n","train_df = pd.read_csv(BASE_PATH+'/train.csv')\n","test_df = pd.read_csv(BASE_PATH+'/test.csv')\n","train_df['category'] = train_df['experiment'].apply(lambda x: x.split('-')[0])\n","test_df['category'] = test_df['experiment'].apply(lambda x: x.split('-')[0])\n","train_df['cell'] = train_df.id_code.str[0:2]\n","test_df['cell'] = test_df.id_code.str[0:2]\n","train_target_df = pd.get_dummies(train_df.cell)\n","test_target_df = pd.get_dummies(test_df.cell)\n","train_idx, val_idx = train_test_split(train_df.index, test_size=0.15, random_state=2019)\n","print(train_idx.shape, val_idx.shape) #(31037,) (5478,) (62075,) (10955,)\n","train_generator = DataGenerator(train_idx, mode='train', df=train_df, target_df=train_target_df, n_classes=train_target_df.shape[1])\n","val_generator = DataGenerator(val_idx, mode='test', df=test_df, target_df=test_target_df, n_classes=test_target_df.shape[1])\n","model = build_model(input_shape=(400, 400, 3), n_classes=train_target_df.shape[1])\n","#model = load_model('model.h5')\n","model.summary()\n","\n","#Train.\n","checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n","history = model.fit_generator(train_generator, validation_data=val_generator, callbacks=[checkpoint], use_multiprocessing=True, verbose=1, epochs=10)\n","\n","with open('history.json', 'w') as f:\n","    json.dump(history.history, f)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(62075,) (10955,)\n","Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_9 (InputLayer)            (None, 400, 400, 3)  0                                            \n","__________________________________________________________________________________________________\n","input_10 (InputLayer)           (None, 400, 400, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 98, 98, 96)   34944       input_9[0][0]                    \n","                                                                 input_10[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_9 (MaxPooling2D)  (None, 49, 49, 96)   0           conv2d_13[0][0]                  \n","                                                                 conv2d_13[1][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 49, 49, 96)   384         max_pooling2d_9[0][0]            \n","                                                                 max_pooling2d_9[1][0]            \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 45, 45, 256)  614656      batch_normalization_13[0][0]     \n","                                                                 batch_normalization_13[1][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_10 (MaxPooling2D) (None, 22, 22, 256)  0           conv2d_14[0][0]                  \n","                                                                 conv2d_14[1][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 22, 22, 256)  1024        max_pooling2d_10[0][0]           \n","                                                                 max_pooling2d_10[1][0]           \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 384)  885120      batch_normalization_14[0][0]     \n","                                                                 batch_normalization_14[1][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 20, 20, 384)  1536        conv2d_15[0][0]                  \n","                                                                 conv2d_15[1][0]                  \n","__________________________________________________________________________________________________\n","global_average_pooling2d_5 (Glo (None, 384)          0           batch_normalization_15[0][0]     \n","                                                                 batch_normalization_15[1][0]     \n","__________________________________________________________________________________________________\n","dense_17 (Dense)                (None, 4096)         1576960     global_average_pooling2d_5[0][0] \n","                                                                 global_average_pooling2d_5[1][0] \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 4096)         0           dense_17[0][0]                   \n","                                                                 dense_17[1][0]                   \n","__________________________________________________________________________________________________\n","dense_18 (Dense)                (None, 2048)         8390656     add_5[0][0]                      \n","__________________________________________________________________________________________________\n","dense_19 (Dense)                (None, 1024)         2098176     dense_18[0][0]                   \n","__________________________________________________________________________________________________\n","dense_20 (Dense)                (None, 4)            4100        dense_19[0][0]                   \n","==================================================================================================\n","Total params: 13,607,556\n","Trainable params: 13,606,084\n","Non-trainable params: 1,472\n","__________________________________________________________________________________________________\n","Epoch 1/10\n","  14/1939 [..............................] - ETA: 9:14:10 - loss: 0.6003 - acc: 0.7768"],"name":"stdout"},{"output_type":"stream","text":["Process ForkPoolWorker-16:\n","Traceback (most recent call last):\n","Process ForkPoolWorker-15:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n","    task = get()\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n","    task = get()\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tCxbLiQ8_WYK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}